<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloudmesh â€“ Old</title>
    <link>/modules/old/</link>
    <description>Recent content in Old on Cloudmesh</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/modules/old/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Modules: Cloudmesh Version 4</title>
      <link>/modules/old/version-4/</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/modules/old/version-4/</guid>
      <description>
        
        
        &lt;p&gt;Cloudmesh version 4 is documented at the following&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;p&gt;Multicloud VM and Data Interfaces to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS&lt;/li&gt;
&lt;li&gt;Azure&lt;/li&gt;
&lt;li&gt;Google&lt;/li&gt;
&lt;li&gt;Oracle&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: FAQ</title>
      <link>/modules/old/faq/</link>
      <pubDate>Tue, 09 Apr 2019 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/faq/</guid>
      <description>
        
        
        &lt;p&gt;This section will include a number of FAQs&lt;/p&gt;
&lt;p&gt;Are there any screenshots?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A number of screenshots are available to showcase some of the
Cloudmesh features at &lt;code&gt;screenshots&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;TODO: link missing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Can I install Cloudmesh on my local computer?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cloudmesh has been used on macOS, Linux, and Windows Computers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How do I get started?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See: &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Can I use Cloudmesh to connect to OpenStack clouds, AWS, Azure, Google,
Oracle Clouds?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Yes you can. We have had users using all such clouds. You can
configure it as documented in the manaual.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Can I participate in the development?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Yes, Yes, Yes. We love your participation. If you have ideas or want
to help on extending Cloudmesh, or even documentation, testing and
code cleanup let us know. You will be properly acknowledged in our
future releases.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I would like to contribute my code to Cloudmesh.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Yes, you can do that. We can create a repository for you on
Cloudmesh. We need to discuss and agree how to best integrate your
code. Please contact us.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh Version 3</title>
      <link>/modules/old/version-3/</link>
      <pubDate>Wed, 11 Apr 2018 11:13:32 -0400</pubDate>
      
      <guid>/modules/old/version-3/</guid>
      <description>
        
        
        &lt;p&gt;TBD&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh Version 2</title>
      <link>/modules/old/version-2/</link>
      <pubDate>Sun, 09 Apr 2017 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/version-2/</guid>
      <description>
        
        
        &lt;p&gt;TBD.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: About2</title>
      <link>/modules/old/about/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/about/</guid>
      <description>
        
        
        &lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;p&gt;We are working towards providing the following features into cloudmesh:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;easy management of multiple clouds in cloudmesh while supporting
various native libraries.&lt;/li&gt;
&lt;li&gt;portability library to access information in regards to images,
flavors, and vms&lt;/li&gt;
&lt;li&gt;management of hundreds/thousands of virtual machines&lt;/li&gt;
&lt;li&gt;integration of non FutureGrid cLouds by users into cloudmesh so
users can access them from cloudmesh&lt;/li&gt;
&lt;li&gt;a command line shell&lt;/li&gt;
&lt;li&gt;a web interface&lt;/li&gt;
&lt;li&gt;possibility to download and deploy cloudmesh locally by a user (so
he can manage his own clouds)&lt;/li&gt;
&lt;li&gt;others&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bugs&#34;&gt;Bugs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AWS, Azure, and EC2 images can not yet be handled well in the data
tables if there are thousands of entries.&lt;/li&gt;
&lt;li&gt;Adding an arbitrary cloud has not yet been enabled, although it can
be achieved via adding it from the command line&lt;/li&gt;
&lt;li&gt;The asynchronous refresh has not yet been enabled&lt;/li&gt;
&lt;li&gt;The look of the table in server does not yet look nice on the header
level (alignment)&lt;/li&gt;
&lt;li&gt;keys for Azure and AWS vms are not yet managed via cloudmesh&lt;/li&gt;
&lt;li&gt;certificates from AWS, and Azure are not yet uploadable by the user&lt;/li&gt;
&lt;li&gt;AWS, and Azure return a large number of images. data tables may have
to be switched all to server side data tables.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-contributors&#34;&gt;Project Contributors&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh&#34;&gt;Cloudmesh&lt;/a&gt; is a community
project and has received contributions from 12 developers. Their names
and contributions to the code are maintained in Github and you can find
out more information about each individual contributor from out &lt;a href=&#34;/git&#34;&gt;Github
Project Page&lt;/a&gt; .&lt;/p&gt;
&lt;h2 id=&#34;contact&#34;&gt;Contact&lt;/h2&gt;
&lt;p&gt;To find more out about cloud mesh &lt;a href=&#34;/contact&#34;&gt;please contact us&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;history&#34;&gt;History&lt;/h2&gt;
&lt;h3 id=&#34;cloudmesh-01&#34;&gt;Cloudmesh 0.1&lt;/h3&gt;
&lt;p&gt;Cloudmesh is part of the effort of FutureGrid to provide a simple
experiment management functionality. It has been used at IU for about 9
month.&lt;/p&gt;
&lt;p&gt;Originally cloudmesh was just a &lt;a href=&#34;https://github.com/futuregrid/cm&#34;&gt;command line
tool&lt;/a&gt; that was able to start hundreds
of VMs on various clouds in order to conduct stress testing of cloud
deployments. There was no comparable tool available. Our requirements
were simple, but none of the tools fulfilled the following requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start hundreds of VMs from the command line with a simple command&lt;/li&gt;
&lt;li&gt;delete the VMs from a user through the command line&lt;/li&gt;
&lt;li&gt;provide native support of the cloud and not just using a wrapper
library such as libcloud or a standard such as OCCI (we wanted to
debug the cloud and not the wrapper libraries or standards)&lt;/li&gt;
&lt;li&gt;provide an elementary display on which VMs run where.&lt;/li&gt;
&lt;li&gt;users should be able to deploy a stand alone version of cloudmesh&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Through this tool we were able to identify issues with our clouds and
improve the deployment.&lt;/p&gt;
&lt;p&gt;Other tools that we tried to use were hiding these issues as they for
example did not use the native API protocol, but instead used
alternative protocols such as EC2 in case of our OpenStack clouds. As a
user this may be ok, but as a resource provider such limitation is
naturally problematic.&lt;/p&gt;
&lt;h3 id=&#34;cloudmesh-02&#34;&gt;Cloudmesh 0.2&lt;/h3&gt;
&lt;p&gt;Next we replaced the curses based user interface with a web browser
based user interface. This made it possible to more easily develop more
sophisticated interfaces in General.&lt;/p&gt;
&lt;p&gt;At the same time we reused our python command shell interpreter cmd3 so
that it is more easily possible to develop command line tools
automatically from the commands we already developed as part of the
command shell anyways.&lt;/p&gt;
&lt;p&gt;A command shell is obviously important as it allows us to describe
experiments as scripts.&lt;/p&gt;
&lt;h3 id=&#34;cloudmesh-03&#34;&gt;Cloudmesh 0.3&lt;/h3&gt;
&lt;p&gt;Base on the success from the earlier versions and the use of a web
browser as interface, it became clear that users could benefit from our
effort. Thus we started to generalize the framework a bit and work
towards distributing cloudmesh as a single user environment while users
can install a stand alone version of the software.&lt;/p&gt;
&lt;p&gt;Based on this internal success of cloudmesh we started thinking it would
be good to expose the functionality also to users.&lt;/p&gt;
&lt;h3 id=&#34;cloudmesh-04&#34;&gt;Cloudmesh 0.4&lt;/h3&gt;
&lt;p&gt;In cloudmesh 0.4 we transformed the store of the VM, flavor, and images
into a database, we also moved the development of the code in a new
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh&#34;&gt;Github Cloudmesh&lt;/a&gt; repository.&lt;/p&gt;
&lt;h3 id=&#34;cloudmesh-05---07&#34;&gt;Cloudmesh 0.5 - 0.7&lt;/h3&gt;
&lt;p&gt;The following important changes took place:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;introduction of a role based authentication theme&lt;/li&gt;
&lt;li&gt;adding FG authentication from the portal account&lt;/li&gt;
&lt;li&gt;ingesting users either from a yaml file or LDAP directory&lt;/li&gt;
&lt;li&gt;adding capabilities to list vms, flavors, and images from AWS&lt;/li&gt;
&lt;li&gt;adding capabilities to list vms, flavors, and images from Azure&lt;/li&gt;
&lt;li&gt;adding capabilities to list vms, flavors, and images from EC2 (via
libcloud)&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh</title>
      <link>/modules/old/o-cloudmesh/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/o-cloudmesh/</guid>
      <description>
        
        
        &lt;p&gt;Cloudmesh is an important component to deliver a software-defined system
&amp;ndash; encompassing virtualized and bare-metal infrastructure, networks,
application, systems and platform software &amp;ndash; with a unifying goal of
providing Cloud Testbeds as a Service (CTaaS). Cloudmesh federates a
number of resources from academia and industry. This includes existing
FutureGrid infrastructure (4704 cores used by more than 355 projects),
Amazon Web Services, Azure, HP Cloud, Karlsruhe using various
technologies.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/cloudmesh-arch-2013.png&#34; alt=&#34;Figure: The cloudmesh architecture. Green = components available,under improvement. Yellow = components underdevelopment.&#34;&gt;&lt;/p&gt;
&lt;p&gt;A goal of Cloudmesh is to aggregate resources not only from FutureGrid,
but also from OpenCirrus, Amazon, Microsoft Azure, and HP Cloud and GENI
resources to name only a few. Cloudmesh was originally developed in
order to simplify the execution of multiple concurrent experiments on a
federated cloud infrastructure. In addition to virtual resources,
FutureGrid exposes bare-metal provisioning to users, but also a subset
of HPC monitoring infrastructure tools. Services will be available
through command line, API, and Web interfaces.&lt;/p&gt;
&lt;p&gt;The three layers of the Cloudmesh architecture include a Cloudmesh
Management Framework for monitoring and operations, user and project
management, experiment planning and deployment of services needed by an
experiment, provisioning and execution environments to be deployed on
resources to (or interfaced with) enable experiment management, and
resources.&lt;/p&gt;
&lt;h2 id=&#34;system-monitoring-and-operations&#34;&gt;System Monitoring and Operations&lt;/h2&gt;
&lt;p&gt;The management framework contains services to facilitate FutureGrid
day-to-day operation, including federated or selective monitoring of the
infrastructure. Cloudmesh leverages FutureGrid for the operational
services and allows administrators to view ongoing system status and
experiments, as well as interact with users through ticket systems and
messaging queues to inform subscribed users on the status of the system.&lt;/p&gt;
&lt;p&gt;The cloudmesh management framework offers services that simplify
integration of resources in the FutureGrid nucleus or through
federation. This includes, for user management, access to predefined
setup templates for services in enabling resource and service
provisioning as well as experiment execution. To integrate IaaS
frameworks cloudmesh offers two distinct services:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;(a) a federated IaaS frameworks hosted on FutureGrid,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(b) the availability of a service that is hosted on FutureGrid
allowing the &amp;ldquo;integration&amp;rdquo; of IaaS frameworks through user
credentials either registered by the users or automatically obtained
from our distributed user directory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For (b) several toolkits exist to create user-based federations,
including our own abstraction level which supports interoperability via
libcloud, but more importantly it supports directly the native OpenStack
protocol and overcomes limitations of the EC2 protocol and the libcloud
compatibility layer. Plugins that we currently develop will enable
access to clouds via firewall penetration, abstraction layers for clouds
with few public IP addresses and integration with new services such as
OpenStack Heat. We successfully federated resources from Azure, AWS, the
HP cloud, Karlsruhe Institute of Technology Cloud, and four FutureGrid
clouds using various versions of OpenStack and Eucalyptus. The same will
be done for OpenCirrus resources at GT and CMU through firewalls or
proxy servers.&lt;/p&gt;
&lt;p&gt;Additional management flexibility will be introduced through automatic
cloud-bursting and shifting services. While cloud bursting will locate
empty resources in other clouds, cloud shifting will identify unused
services and resources, shut them down and provision them with services
that are requested by the users. We have demonstrated this concept in
2012, moving resources for ~100 users to services that were needed
based on class schedules. A reservation system will be used to allow for
reserved creation of such environments, along with improvements of
automation of cloud-shifting.&lt;/p&gt;
&lt;h2 id=&#34;user-and-project-services&#34;&gt;User and Project Services&lt;/h2&gt;
&lt;p&gt;FutureGrid user and project services simplify the application processes
needed to obtain user accounts and projects. We have demonstrated in
FutureGrid the ability to create accounts in a very short time,
including vetting projects and users &amp;ndash; allowing fast turn-around times
for the majority of FutureGrid projects with an initial startup
allocation. Cloudmesh re-uses this infrastructure and also allows users
to manage proxy accounts to federate to other IaaS services to provide
an easy interface to integrate them.&lt;/p&gt;
&lt;h3 id=&#34;accounting-and-app-store&#34;&gt;Accounting and App Store&lt;/h3&gt;
&lt;p&gt;To lower the barrier of entry Cloudmesh will be providing a shopping
cart which will allow checking out of predefined repeatable experiment
templates. A cost is associated with an experiment making it possible to
engage in careful planning and to save time by reusing previous
experiments. Additionally, the Cloudmesh App Store may function as a
clearing-house of images, image templates, services offered and
provisioning templates. Users may package complex deployment
descriptions in an easy parameter/form-based interface and other users
may be able to replicate the specified setup with.&lt;/p&gt;
&lt;p&gt;Due to our advanced Cloudmesh Metrics framework we are in the position
to further develop an integrated accounting framework allowing a usage
cost model for users and management to identify the real impact of an
experiment on resources. This will be useful to avoid overprovisioning
and inefficient resource usage. The cost model will be based not only on
number of core hours used, but also the capabilities of the resource,
the time, and special support it takes to set up the experiment. We will
expand upon the metrics framework of FutureGrid that allows measuring of
VM and HPC usage and associate this with cost models. Benchmarks will be
used to normalize the charge models.&lt;/p&gt;
&lt;h3 id=&#34;networking&#34;&gt;Networking&lt;/h3&gt;
&lt;p&gt;We have a broad vision of resource integration in FutureGrid with
systems offering different levels of control from &amp;quot;bare metal&amp;quot; to use
of a portion of a resource. Likewise, we must utilize networks offering
various levels of control, from standard IP connectivity to completely
configurable SDNs as novel cloud architectures will almost certainly
leverage NaaS and SDN alongside system software and middleware.
FutureGrid resources will make use of SDN using OpenFlow whenever
possible and the same level of networking control will not be available
in every location.&lt;/p&gt;
&lt;h3 id=&#34;monitoring&#34;&gt;Monitoring&lt;/h3&gt;
&lt;p&gt;To serve the purposes of CISE researchers, Cloudmesh must be able to
access empirical data about the properties and performance of the
underlying infrastructure beyond what is available from commercial cloud
environments. To accommodate this requirement we have developed a
uniform access interface to virtual machine monitoring information
available for OpenStack, Eucalyptus, and Nimbus. In the future, we will
be enhancing the access to historical user information. Right now they
are exposed through predefined reports that we create on a regular
basis. To achieve this we will also leverage the ongoing work while
using the AMPQ protocol. Furthermore, Cloudmesh will provide access to
common monitoring infrastructure as provided by Ganglia, Nagios, Inca,
perfSonar, PAPI and others.&lt;/p&gt;
&lt;h3 id=&#34;role-and-use-of-standards-and-open-source-software&#34;&gt;Role and Use of Standards and Open Source Software&lt;/h3&gt;
&lt;p&gt;Cloudmesh will use standards and open source software as part of its
design principles towards sustainability. We will leverage efforts such
as OCCI and CDMI and are already using community efforts on
interoperability APIs as provided by Apache libcloud. However, as
libcloud is feature limited Cloudmesh provides an additional abstraction
layer that exposes cloud interfaces on the native-protocol level.
Furthermore we interface to commercial Clouds such as Microsoft Azure,
Amazon WS, and HP Cloud to providing access to robust commercial high
availability services.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh 1</title>
      <link>/modules/old/o-cloudmesh-1/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/o-cloudmesh-1/</guid>
      <description>
        
        
        &lt;p&gt;At this time we are focussing on Cloudmesh 3 and are not using Cloudmesh
1 features. However Cloudmesh 1 could still be useful.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Feature               Description                                         Image&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cloudmesh Core        A project to interface easily with multiple clouds  &lt;img src=&#34;_static/cloud_register_openstack.png&#34; alt=&#34;image-registry&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
from the command line and a command shell.       &lt;br&gt;
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh&#34;&gt;github&lt;/a&gt;,&lt;br&gt;
&lt;a href=&#34;http://cloudmesh.github.io/cloudmesh/&#34;&gt;doc&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Convenient Command    Cloudmesh contains a nice command shell that goes   &lt;img src=&#34;_static/cmd3.png&#34; alt=&#34;image-cmd3&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
Shell                 beyond a simple commandline interface. State can be
saved between command invocations.&lt;/p&gt;
&lt;p&gt;Cloudmesh Metric for  Cloudmesh contains a metric report system that id   &lt;img src=&#34;_static/metric.png&#34; alt=&#34;image-metric&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
Clouds                used can provide customized reports.&lt;/p&gt;
&lt;p&gt;Cloudmesh Inventory   Cloudmesh has a simple inventory that allows system &lt;img src=&#34;_static/inventory.png&#34; alt=&#34;image-inventory&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
administrators and users to easily manage resource&lt;br&gt;
inventory in inventory datatables. The attributes&lt;br&gt;
in that table can be defined by the user&lt;/p&gt;
&lt;p&gt;Cloudmesh PaaS        Cloudmesh has the ability to interface with various &lt;img src=&#34;_static/launcher.png&#34; alt=&#34;image-launcher&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
Launcher              DevOps frameworks. Through them we expose via    &lt;br&gt;
simple command tools the ability to conveniently &lt;br&gt;
launch platforms. Examples are virtual clusters on&lt;br&gt;
OpenStack, Apache storm and others. We have an easy
way to integrate additional platforms into the   &lt;br&gt;
command shell through an automatic code generator&lt;br&gt;
for command additions.&lt;/p&gt;
&lt;p&gt;Cloudmesh Federated   Cloudmesh allows the federated management of VMs    &lt;img src=&#34;_static/manage_vms.png&#34; alt=&#34;image-manage-vms&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
VMs                   through one interface. This allows us to use     &lt;br&gt;
CLoudmesh as an onramp&lt;/p&gt;
&lt;p&gt;Cloudmesh HPC Batch   Cloudmesh includes the ability to view HPC queues.  &lt;img src=&#34;_static/qinfo.png&#34; alt=&#34;image-qinfo&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
Processing            Most recently we have added a simple API to also    &lt;img src=&#34;_static/qstat.png&#34; alt=&#34;image-qstat&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
submit jobs. Our goal is to be able to manage    &lt;br&gt;
millions of jobs submitted to a Computational Grid,
but also user managed heterogeneous sets of      &lt;br&gt;
clusters that may not be port of a national or   &lt;br&gt;
international Grid infrastructure.&lt;/p&gt;
&lt;h2 id=&#34;as-temperature-of-the-servers&#34;&gt;Cloudmesh Service Map For locally maintained resources, Cloudmesh         &lt;img src=&#34;_static/service_map.png&#34; alt=&#34;image-service-map&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}
provides the ability to visualize a service map. We
will be expanding upon this effort to integrate  &lt;br&gt;
with our new inventory. This makes it possible to&lt;br&gt;
for example display services mapped onto compute &lt;br&gt;
servers, but also concrete sensor information such&lt;br&gt;
as temperature of the servers&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh cmd3</title>
      <link>/modules/old/o-cloudmesh-cmd3/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/o-cloudmesh-cmd3/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;2016 - 2017&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-cmd3&#34;&gt;https://github.com/cloudmesh-cmd3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;base&lt;/li&gt;
&lt;li&gt;cloudmesh&lt;/li&gt;
&lt;li&gt;client portal&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh Version 1</title>
      <link>/modules/old/version-1/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/version-1/</guid>
      <description>
        
        
        &lt;p&gt;TBD.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Cloudmesh Version 1: Screenshots</title>
      <link>/modules/old/screenshot/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/screenshot/</guid>
      <description>
        
        
        &lt;p&gt;Please note that cloudmesh supports a role based user policy model.
Although you may see some screenshots of advanced features some of these
features may not yet released to the users.&lt;/p&gt;
&lt;h2 id=&#34;cloud-management&#34;&gt;Cloud Management&lt;/h2&gt;
&lt;p&gt;Cloudmesh has a simple interface to register and conduct some elementary
management functions. In contrast to other systems cloudmesh uses the
native cloud protocol and is not just relying on the EC2 compatible
clouds. Certainly the Graphical user interface can be improved and
customized. We have just provided a very simple interface that focuses
on exposing more info that encourages you to conduct more with the
management functionality instead of just hiding information to the user.
For end-users, we can naturally develop a much simpler interface, as for
example is demonstrated in our launcher (which is not yet released).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/cloud_register_openstack.png&#34; alt=&#34;Figure: Registering an OpenStack protocol compatible cloud.&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Registering an OpenStack protocol compatible cloud.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/cloud_register_ec2.png&#34; alt=&#34;Figure: Registering an EC2 compatible cloud&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Registering an EC2 compatible cloud.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/manage_vms.png&#34; alt=&#34;Figure: Starting and deletion of VMs is easy in cloudmesh through a simple table view.&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Starting and deletion of VMs is easy in cloudmesh through a simple table view.&lt;/p&gt;
&lt;h2 id=&#34;provisioningraining&#34;&gt;Provisioning/Raining&lt;/h2&gt;
&lt;p&gt;Cloudmesh contains the ability to provision a server via bare metal
access by the users. To simplify this already available access we are
currently developing a simpler interface to it. We have already
implemented a policy based access control that allows a role based
access based on projects and users. In near future we will integrate our
bare metal provisioning management. features into this system.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/launcher.png&#34; alt=&#34;Figure: Launching predefined configurations on FutureGrid.&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Launching predefined configurations on FutureGrid.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/provisioning_policy.png&#34; alt=&#34;Figure: Defining the baremetal access policy&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Defining the baremetal access policy.&lt;/p&gt;
&lt;h2 id=&#34;batch-queues&#34;&gt;Batch Queues&lt;/h2&gt;
&lt;p&gt;Hadoop is often installed on a cluster. Thus having access to the queues
to monitor queue based resource reservation for Hadoop jobs (or and
other HPC job) is conveniently provided in cloudmesh. Launchers (under
development) can be used to easily interface with the systems and
conduct customized job creation. Via MyHadoop for example it is possible
to start Hadoop jobs in queues on FutureGrid.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/qinfo.png&#34; alt=&#34;Figure: Listing the available queues.&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Listing the available queues.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/qstat.png&#34; alt=&#34;Figure: Listing the queue information about jobs and status&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Listing the queue information about jobs and status.&lt;/p&gt;
&lt;h2 id=&#34;status&#34;&gt;Status&lt;/h2&gt;
&lt;p&gt;The status of the system will be visible in a status window. Here we
just show a view of the HPC resources. We already have developed a cloud
monitoring system that we intend to integrate soon. For FutureGrid this
system is already deployed via the FG portal.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/status_hpc.png&#34; alt=&#34;Figure: Displaying a simple status of the systems (hereHPC).&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Displaying a simple status of the systems(hereHPC).&lt;/p&gt;
&lt;h2 id=&#34;inventory&#34;&gt;Inventory&lt;/h2&gt;
&lt;p&gt;Often we just need to know sme details about the system. To facilitate
this, we have developed an inventory. In addition we also developed
physical view of the rack that can either be augmented with service type
displays or temperature of the rack.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/inventory.png&#34; alt=&#34;Figure: Inventory of the systems.&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Inventory of the systems.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/service_map.png&#34; alt=&#34;Figure: Service map to depict which server is dedicated to which services.&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Service map to depict which server is dedicated to which services.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cloudmesh/temperature_map.png&#34; alt=&#34;Figure: Temperature map of a rack&#34;&gt;
&lt;strong&gt;Figure:&lt;/strong&gt; Temperature map of a rack&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Hadoop</title>
      <link>/modules/old/hadoop/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/hadoop/</guid>
      <description>
        
        
        &lt;p&gt;Please chose from the following templates to select which version of
Haddop you like to easily install.&lt;/p&gt;
&lt;p&gt;&amp;lt;form&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;font size=&amp;quot;+4&amp;quot;&amp;gt; &amp;lt;table&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;tr&amp;gt; &amp;lt;th&amp;gt;Template &amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; Description&amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; Servers
&amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; Cost &amp;lt;/th&amp;gt; &amp;lt;tr&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;tr&amp;gt; &amp;lt;td&amp;gt;&amp;lt;img src=&amp;quot;/static/img/hadoop-elephant.jpg&amp;quot; width=&amp;quot;100&amp;quot;
height=&amp;quot;100&amp;quot;&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; This will install hadoop on Linux servers
a resource in ICRISP &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; &amp;lt;input type=&amp;quot;number&amp;quot;
name=&amp;quot;quantity&amp;quot; min=&amp;quot;0&amp;quot; max=&amp;quot;128&amp;quot; value=&amp;quot;64&amp;quot;&amp;gt; &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;
$80.00 &amp;lt;/td&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;tr&amp;gt; &amp;lt;td&amp;gt;&amp;lt;img src=&amp;quot;/static/img/hadoop-microsoft.jpg&amp;quot;
width=&amp;quot;100&amp;quot; height=&amp;quot;100&amp;quot;&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; This will install hadoop on
Microsoft servers a resource in ICRISP &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; &amp;lt;input
type=&amp;quot;number&amp;quot; name=&amp;quot;quantity&amp;quot; min=&amp;quot;0&amp;quot; max=&amp;quot;128&amp;quot; value=&amp;quot;0&amp;quot;&amp;gt;
&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; $0.0 &amp;lt;/td&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;tr&amp;gt; &amp;lt;th&amp;gt; Total &amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; &amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; &amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; $80.0
&amp;lt;/th&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td colspan=&amp;quot;4&amp;quot; align=&amp;quot;right&amp;quot;&amp;gt; &amp;lt;p
align=&amp;quot;right&amp;quot;&amp;gt; &amp;lt;button type=&amp;quot;button&amp;quot;&amp;gt;Checkout&amp;lt;/button&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/td&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/table&amp;gt; &amp;lt;/font&amp;gt; &amp;lt;/form&amp;gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: HPC</title>
      <link>/modules/old/hpc/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/hpc/</guid>
      <description>
        
        
        &lt;p&gt;Cloudmesh provides a simple interface to view High Perfomance Computer
clusters batch queues. This includes a python API, iPython examples, a
hosted user interface and a stand alone user interface. Currently we
support Torques qstat and qinfo. An interface for pbsnodes is also
available and is used in our service display.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;qinfo&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Information about which queues are available&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;qstat&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Information which jobs ar ecurrently running&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;pbsnodes&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Information about which services are use on a server and set in the
comments of pbs&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: IaaS</title>
      <link>/modules/old/iaas/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/iaas/</guid>
      <description>
        
        
        &lt;p&gt;Cloudmesh IaaS abstratcions provides a convenient set of interfaces to
various clouds. Currently we focus on virtual machine management, but a
future version will include other services.&lt;/p&gt;
&lt;h2 id=&#34;interfaces&#34;&gt;Interfaces&lt;/h2&gt;
&lt;p&gt;The Cloudmesh core interfaces include&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;API&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A python API that simplifies access to clouds while being able o use
the native cloud protocols and not just an EC2 compatibility mode
(e.g. as is provided by &lt;a href=&#34;https://libcloud.apache.org/&#34;&gt;libcloud&lt;/a&gt; or
&lt;a href=&#34;https://github.com/boto/boto#boto&#34;&gt;boto&lt;/a&gt;). However, we are also
providing an EC2 interface based on libcloud, making it possible to
integrate easily the many clouds supported by it.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Shell&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A command shell allows easy interaction with various clouds using
simple commands. As the commands can be included in scripts, it can
also help to formulate simple experiment templates.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Commands&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;The shell commands can also be used on the Unix command line, making
it possible to integrate cloudmesh features into the unix ecosystem.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Web UI&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;On &lt;a href=&#34;https://portal.futuregrid.org/&#34;&gt;FutureGrid&lt;/a&gt;, we are providing an
example for a hosted mode of Cloudmesh. See
&lt;a href=&#34;https://futuregrid.org/cloudmesh&#34;&gt;https://futuregrid.org/cloudmesh&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Console UI&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;It is possible to host Cloudmesh on your own computer. This may be
desirable if you would like to customize the interfaces or develop
support for additional platforms. We would like to hear back from
you if you use it in this fashion. We are also interested in
integrating your new components and features into Cloudmesh. If you
would like to become a developer, please contact
&lt;a href=&#34;mailto:laszewski@gmail.com&#34;&gt;laszewski@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;iPython&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;We are currently developing a set of simple examples to let users
know how easy it is to use the API.&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;h2 id=&#34;integration-of-external-clouds&#34;&gt;Integration of External Clouds&lt;/h2&gt;
&lt;p&gt;Currently we support the native OpenStack and the EC2 protocols. This
allows you to integrate a large number of clouds, not just FutureGrid
Cloud resources. However, some clouds require use of a certificate. In
this case you can talk to us.&lt;/p&gt;
&lt;p&gt;We have successfully demonstrated integration with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack Grizzly clouds, an example is sierra.futuregrid.org&lt;/li&gt;
&lt;li&gt;EC2 OpenStack cloud, an example is alamo.futuregrid.org&lt;/li&gt;
&lt;li&gt;HP Cloud East&lt;/li&gt;
&lt;li&gt;HP Cloud West&lt;/li&gt;
&lt;li&gt;Karlsruhe Institute of Technology&lt;/li&gt;
&lt;li&gt;Azure (standalone mode)&lt;/li&gt;
&lt;li&gt;AWS (standalone mode)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although we have demonstrated that it is possible to integrate with
Cloudmesh we have not yet exposed this feature by default. Users are
welcome to try it.&lt;/p&gt;
&lt;h2 id=&#34;open-source&#34;&gt;Open Source&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Apache&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Cloudmesh is distributed with the Apache 2.0 license&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Github&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Cloudmesh is hosted on github.gom. More information is provided at
&lt;a href=&#34;/git&#34;&gt;our github page&lt;/a&gt;.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Bugs&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;You can submit bugs through the FutureGrid help page at
&lt;a href=&#34;https://portal.futuregrid.org/help&#34;&gt;https://portal.futuregrid.org/help&lt;/a&gt;.&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: News</title>
      <link>/modules/old/news/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/news/</guid>
      <description>
        
        
        &lt;p&gt;We are happy to announce the alpha release of cloudmesh. Cloudmesh is
capable of interfacing with clouds and HPC frameworks. We have
successfully demonstarted by our developers usage of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack Clouds on FutureGrid (India, Sierra, Alamo)&lt;/li&gt;
&lt;li&gt;AWS&lt;/li&gt;
&lt;li&gt;Azure&lt;/li&gt;
&lt;li&gt;HP Cloud&lt;/li&gt;
&lt;li&gt;Karlsruhe Institute of Technolgy Cloud&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this time we only expose the FutuureGrid Sierra OpenStack cloud. We
like to acknowledge all those that helped us developing Cloudmesh.&lt;/p&gt;
&lt;p&gt;Thanks&lt;/p&gt;
&lt;p&gt;Gregor von Laszewski and the rest of&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/git&#34;&gt;the cloudmesh team&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Projects</title>
      <link>/modules/old/projects/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/projects/</guid>
      <description>
        
        
        &lt;p&gt;We are working on a number of development projects. Instead of just
providing a single project, we decided to split the development up into
smaller subprojects. This allows the groups to work independently and
avoids the problem that a compile error in one code causes an issue in
another. All projects listed here are managed in github.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Image                                                          Project           Description                      Source&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;images/cloudmesh-arch-2013.png&#34; alt=&#34;image-arch&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}   Cloudmesh Core    A project to interface easily    &lt;a href=&#34;https://github.com/cloudmesh/cloudmesh&#34;&gt;github&lt;/a&gt;,
with multiple clouds from the    &lt;a href=&#34;http://cloudmesh.github.io/cloudmesh/&#34;&gt;doc&lt;/a&gt;
command line and a command    &lt;br&gt;
shell.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;_static/cmd3.png&#34; alt=&#34;image-cmd3&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}                 CMD3              A dynamic CMD shell with         &lt;a href=&#34;https://github.com/cloudmesh/cmd3&#34;&gt;github&lt;/a&gt;,
plugins, scripts, and variables  &lt;a href=&#34;http://cloudmesh.github.io/cmd3/&#34;&gt;doc&lt;/a&gt;
and IEEE compliant man pages&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;_static/rain.png&#34; alt=&#34;image-rain&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}                 Rain              A project to do bare metal and   &lt;a href=&#34;https://github.com/futuregrid/rain&#34;&gt;github&lt;/a&gt;
VM based dynamic provisioning    &lt;a href=&#34;http://futuregrid.github.io/rain/&#34;&gt;doc&lt;/a&gt;
for a HPC cluster, OpenStack, &lt;br&gt;
Eucalyptus.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                             Rain-Move         An extension to rain that allows [github](https://github.com/futuregrid/rain-move),
                                                                               to move resources between        [doc](http://futuregrid.github.io/rain-move/)
                                                                               different IaaS, Bare metal, and  
                                                                               HPC services.                    
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;_static/teefaa.png&#34; alt=&#34;image-teefaa&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}             Teefaa            A project to dynamically         &lt;a href=&#34;https://github.com/cloudmesh/teefaa&#34;&gt;github&lt;/a&gt;,
provision operating systems.     &lt;a href=&#34;http://cloudmesh.github.io/teefaa/&#34;&gt;doc&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;_static/metric.png&#34; alt=&#34;image-metric&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}             Cloud-Metrics     A project to measure and display &lt;a href=&#34;https://github.com/futuregrid/cloud-metrics&#34;&gt;github&lt;/a&gt;,
metric information about usage   &lt;a href=&#34;http://futuregrid.github.io/cloud-metrics/&#34;&gt;doc&lt;/a&gt;
and utilization of your cloud.   &lt;a href=&#34;https://github.com/futuregrid/cloud-accounting&#34;&gt;github&lt;/a&gt;
&lt;a href=&#34;https://portal.futuregrid.org/doc/metric/index.html&#34;&gt;Example&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;_static/vcluster.png&#34; alt=&#34;image-vcluster&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}         Virtual-Cluster   A project to create a SLURM      &lt;a href=&#34;https://github.com/futuregrid/virtual-cluster&#34;&gt;github&lt;/a&gt;,
based cluster in your cloud and  &lt;a href=&#34;http://futuregrid.github.io/virtual-cluster/&#34;&gt;doc&lt;/a&gt;
run MPI jobs on it.&lt;/p&gt;
&lt;h2 id=&#34;for-the-project------------------githubhttpsgithubcomfuturegridportal&#34;&gt;&lt;img src=&#34;_static/portal.png&#34; alt=&#34;image-portal&#34;&gt;{width=&amp;ldquo;100px&amp;rdquo;}             Portal            A project to do develop a portal &lt;a href=&#34;http://portal.futuregrid.org/&#34;&gt;www&lt;/a&gt;
for the project                  &lt;a href=&#34;https://github.com/futuregrid/portal&#34;&gt;github&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;: Projects&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Rain</title>
      <link>/modules/old/rain/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/rain/</guid>
      <description>
        
        
        &lt;p&gt;Cloudmesh provides a convenient interface to baremetal access of
resources and to provision services on these bare metal resources. We
term this concept &lt;strong&gt;rain&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Rain is integrated into the cloudmesh UI through a role based access
control mechanism allowing either specific users or specific projects to
gain access. Furthermore, users and projects can be restricted in which
reosurces the users have access to. This is of special importance to be
able to conduct successive experiments on the exact same resources.&lt;/p&gt;
&lt;p&gt;Although we can enable a scheduler based interface to bare metal
provisioning, the our current rol based, resource reserveration provides
the user with more access to specific experiment setups.&lt;/p&gt;
&lt;p&gt;The following provisioning conccepts are important and are included in
rain&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Baremetal&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;bare metal provisioning provides the ability to provisin an OS
directly on the server.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Service&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;services can be dynamically provisioned either via bare metal or
IaaS provisioning.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Platform&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A combination of bare metal, IaaS, and service provisioning may
provide users with a platform. Instead of users needing to put
together such a platform, they can benefit from previous
instantiations and templates developed by others.&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: References</title>
      <link>/modules/old/bib/</link>
      <pubDate>Sat, 09 Apr 2016 10:58:08 -0400</pubDate>
      
      <guid>/modules/old/bib/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;General FutureGrid:&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Cloud Comparison:&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Rain and Image Management:&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Cloud Metric&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Others&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Design of the FutureGrid Experiment Management Framework&lt;/strong&gt;,
Gregor von Laszewski, Geoffrey C. Fox, Fugang Wang, Andrew Younge,
Andrew, A Kulshrestha, Gregory G. Pike, Warren Smith, Jens Voeckler,
Renato J. Figueiredo, Jose Fortes, Kate Keahey, Ewa Deelman,
Proceedings of Gateway Computing Environments 2010 (GCE2010) at
SC10, 2010, New Orleans, LA, Nov, IEEE, DOI
10.1109/GCE.2010.5676126,
&lt;a href=&#34;http://cyberaide.googlecode.com/svn/trunk/papers/10-FG-exp-GCE10/vonLaszewski-10-FG-exp-GCE10.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;FutureGrid - a reconfigurable testbed for Cloud, HPC, and Grid
Computing&lt;/strong&gt;, Fox, Geoffrey and Gregor von Laszewski and Javier Diaz
and Kate Keahey and Jose Fortes and Renato Figueiredo and Smallen,
Shava and Warren Smith and Andrew Grimshaw, Contemporary High
Performance Computing: From Petascale toward Exascale, CRC
Computational Science, Apr. 2013, Chapman and Hall, DOI
&lt;a href=&#34;http://www.crcnetbase.com/doi/pdf/10.1201/b14677-6&#34;&gt;www.crcnetbase.com/doi/pdf/10.1201/b14677-6&lt;/a&gt;â€Ž, Editor J. Vetter,
&lt;a href=&#34;http://cyberaide.googlecode.com/svn/trunk/papers/pdf/vonLaszewski-12-fg-bookchapter.pdf&#34;&gt;(PDF)&lt;/a&gt;, &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Comparison of Multiple Cloud Frameworks&lt;/strong&gt;, Gregor von Laszewski
and Javier Diaz and Fugang Wang and Geoffrey&lt;/p&gt;
&lt;p&gt;C. Fox, IEEE Cloud 2012, Jun. 2012, Honolulu, HI, DOI
10.1109/CLOUD.2012.104,
&lt;a href=&#34;http://cyberaide.googlecode.com/svn/trunk/papers/12-cloud12-cloudcompare/laszewski-IEEECloud2012_id-4803.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Abstract Image Management and Universal Image Registration for
Cloud and HPC Infrastructures&lt;/strong&gt;, Javier Diaz, Gregor von Laszewski,
Fugang Wang and Geoffrey C. Fox, IEEE Cloud 2012, Jun. 2012,
Honolulu, 10.1109/CLOUD.2012.94,
&lt;a href=&#34;http://cyberaide.googlecode.com/svn/trunk/papers/12-cloud12-imagemanagement/vonLaszewski-12-IEEECloud2012.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;FutureGrid Image Repository: A Generic Catalog and Storage
System for Heterogeneous Virtual Machine Images&lt;/strong&gt;, Javier Diaz and
Gregor von Laszewski and Fugang Wang and Younge, Andrew J and
Geoffrey C. Fox, Third IEEE International Conference on Coud
Computing Technology and Science (CloudCom2011), 2011, Pages
560-564, Athens, Greece, 12/2011, DOI 10.1109/CloudCom.2011.85,
&lt;a href=&#34;http://cyberaide.googlecode.com/svn/trunk/papers/11-cloudcom11-imagerepo/vonLaszewski-draft-11-imagerepo.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Rain: Dynamically Provisioning Clouds within FutureGrid&lt;/strong&gt;, Fox,
G. C. and A. J. Younge, G. von Laszewski, A. Kulshrestha, and&lt;/p&gt;
&lt;p&gt;F. Wang, SC10 International Conference for High Performance
Computing, Nov., 2010,
&lt;a href=&#34;http://d2i.indiana.edu/sites/default/files/dynamic_provisioning_poster.ppt&#34;&gt;(PPT)&lt;/a&gt;,
&lt;a href=&#34;http://sc10.supercomputing.org/?pg=posters.html&#34;&gt;(URL)&lt;/a&gt; &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Provisioned Experiments in FutureGrid&lt;/strong&gt;, von Laszewski,
Gregor and Geoffrey C. Fox and von Laszewski, Gregor and Geoffrey C.
Fox and FutureGrid Team, 2nd IEEE International Conference on Cloud
Computing Technology and Science (CloudCom2010), Indianapolis, IN,
12/1/2010, 2010,
&lt;a href=&#34;http://grids.ucs.indiana.edu/ptliupages/presentations/vonLaszewski-10-FG-proj-management.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Design of an Accounting and Metric-basedcloud-shifting and
Cloud-seeding Framework for Federatedclouds and Bare-metal
Environments&lt;/strong&gt;, von Laszewski, Gregor and Lee, Hyungro and Diaz,
Javier and Wang, Fugang and Tanaka, Koji and Karavinkoppa, Shubhada
and Fox, Geoffrey&lt;/p&gt;
&lt;p&gt;C. and Furlani, Tom, Proceedings of the 2012 Workshop on Cloud
Services, Federation, and the 8th Open Cirrus Summit, San Jose,
California, USA, 2012, Pages 25--32, New York, NY, USA, ACM, DOI
10.1145/2378975.2378982, ISBN 978-1-4503-1754-2,
&lt;a href=&#34;http://grids.ucs.indiana.edu/ptliupages/publications/p25-vonLaszewski.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;strong&gt;Supporting Experimental Computer Science&lt;/strong&gt;, Frederic Desprez and
Fox, Geoffrey and Emmanuel Jeannot and Kate Keahey and Michael
Kozuch and David Margery and Pierre Neyron and Lucas Nussbaum and
Christian Perez and Olivier Richard and Warren Smith and Gregor von
Laszewski and Jens Voeckler, Technical Report Memo 326, Argonne
National Laboratory, 03/2012,
&lt;a href=&#34;http://www.nimbusproject.org/downloads/Supporting_Experimental_Computer_Science_final_draft.pdf&#34;&gt;(PDF)&lt;/a&gt; &lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Modules: Contact</title>
      <link>/modules/old/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/modules/old/contact/</guid>
      <description>
        
        
        &lt;p&gt;Please contact Gregor von Laszewski on his Web page at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://laszewski.github.io/&#34;&gt;https://laszewski.github.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or send an e-mail to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;mailto:laszewski@gmail.com&#34;&gt;laszewski@gmail.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
